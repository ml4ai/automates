## Equation Reading

The UA team began the task of equation reading using the open-source `im2markup` model (Deng, Kanervisto & Rush, 2016).  However, while the pre-trained model performed well on the authorsâ€™ data, when used on data from other sources, even after using the same preprocessing pipeline, the decoded equations were not usable (please see detailed results in the month 5 report).  Additionally, because of the way the code was written, any model trained on a GPU (which is necessary due to the complexity of the model and the amount of training) would require a GPU for inference as well.  Finally, when trying to re-train the model on our data, version conflicts with library dependencies are continually causing the model to crash.  

For these reasons, and also because we ultimately want to extend the model, the UA team has reimplemented the model in [PyTorch](https://pytorch.org/), which allows for trained models to be used on either a CPU or a GPU.   Additionally, the reimplementation was intentionally done in a modular way, such that components can be replaced/extended easily.  The team plans to make use of this modularity in the near future to add online data augmentation (to reduce sensitivity to exact input format) and a final layer to the equation decoder which will choose the globally optimal equation, rather than greedily making decoding decisions at each time step.  

The UA team is in the process of building a [Singularity](https://singularityhub.com/) container to train the model on the [UA HPC](https://it.arizona.edu/service/high-performance-computing).  Once that is completed, the team will ensure that their reimplementation can approximately reproduce the results of the original, and will then begin working on the needed extensions to improve model performance for our use case.