TextEngine {
  // Override the default values here
//  basePath = /org/clulab/aske_automates
//  masterRulesPath = ${OdinEngine.basePath}/grammars/master.yml
//  entityRulesPath = ${OdinEngine.basePath}/grammars/entities/grammar/entities.yml
//  avoidRulesPath = ${OdinEngine.basePath}/grammars/avoidLocal.yml
//  taxonomyPath = ${OdinEngine.basePath}/grammars/taxonomy.yml
//  maxHops = 15

//  documentFilter = "length"
  preprocessorType = "Light" // "PassThrough" is for the webapp, "Light" (get rid of non-language looking strings and extra long words), "EdgeCase" for docs that have both prose and tables of contents and such
  enableExpansion = true
  validArgs = ["description"] #which args are to be expanded
  freqWordsPath = "./src/main/resources/frequentWords.tsv"


  entityFinder {
    enabled = true
    finderTypes = ["rulebased", "gazetteer"]

    // Rule-based
    entityRulesPath = ${TextEngine.basePath}/grammars/entities/grammar/entities.yml
    avoidRulesPath = ${TextEngine.basePath}/grammars/entities/grammar/avoid.yml
    maxHops = 15

    // grobid-quantities
    taxonomy = ${TextEngine.taxonomyPath}
    domain = "localhost"
    port = "8060"

    // Gazetteer
    lexicons = ["unit.tsv", "GreekLetter.tsv"]
  }


}

CommentEngine {
//  basePath = /org/clulab/aske_automates
  masterRulesPath = ${TextEngine.basePath}/grammars/comments/master.yml
  taxonomyPath = ${TextEngine.taxonomyPath}

  enableLexiconNER = true
  enableExpansion = false
  validArgs = ${TextEngine.validArgs}
  preprocessorType = "EdgeCase"
  documentFilter = "length"
  freqWordsPath = ${TextEngine.freqWordsPath}

  entityFinder {
    enabled = true
    finderTypes = ["grfn"]

    // GrFN-based string match
    grfnFile = ${apps.grfnFile}

  }
}


apps {
 // projectDir = "/Users/alexeeva/Repos/automates"
  projectDir = "/automates"
  //grfnFile = "path/to/PETPT_GrFN.json"
  inputDirectory = "./input/SIR/text"

  inputType = "json"

  predictedEquations = "/local/path/to/PETPT_equations.txt"

  numAlignments = 3
  numAlignmentsSrcToComment = 3
  scoreThreshold = 0.0
  maxSVOgroundingsPerVar = 5
  groundToSVO = false
  groundToWiki = false
  saveWikiGroundingsDefault = false
  numOfWikiGroundings = 3
  appendToGrFN = true
  debug = true
  commentTextAlignmentScoreThreshold = -1.0 //todo: change if the scoring function changes
  serializerName = "AutomatesJSONSerializer" // another option - JSONSerializer: there is a small difference between the two serializers, so the same serializer has to be used to serialize and deserialize mentions

  outputDirectory = "./"

  exportAs =  ["tsv","serialized", "json"] // no other formats yet specified, but can be added!
  loadMentions = true
  mentionsFile = "/local/path/to/PT-mentions.json"
  appendToGrFN = true
  //=====AlignmentBaselineData=====
  baselineDir = "./input/LREC/dev"
  baselineOutputDirectory = "./output/LRECBaseline"
  pdfalignDir = ${apps.projectDir}/automates/apps/pdfalign
  baselineTextInputDirectory = ${apps.baselineDir}/ParsedJsons
  baselineEquationDir = ${apps.baselineDir}/equations
  baselineGoldDir = ${apps.baselineDir}/gold
  baselineAlignedLatexDir = ${apps.baselineDir}/latex_alignments
  eqnPredFile = ${apps.baselineDir}/equations/equationsFromTranslator.txt
  eqnSrcFile = ${apps.baselineDir}/equations/croppedImages.txt
  exportedMentionsDir = ${apps.baselineDir}/extractedMentions
}

alignment {
  alignerType = "pairwisew2v"
  w2vPath = "vectors.txt" // a word embeddings file (e.g., GloVe) with this header: <len_of_vocab><space><embedding_size>, e.g., "6B 50" (no quotes); use of different sets of embeddings will require adjusting alignment similarity thresholds, e.g., commentTextAlignmentScoreThreshold
  relevantArgs = ["variable", "description"] // also possible ["variable"]
}

// if no other changes come to the model comparison alignment, can remove - tbd
modelComparisonAlignment {
  alignerType = "pairwisew2v"
  w2vPath = "vectors.txt"
  relevantArgs = ["description"] // also possible ["variable"]
}

grounding {
  sparqlDir = ${apps.projectDir}/automates/text_reading/sparql
}
